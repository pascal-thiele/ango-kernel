# 1 general design decisions


# system on a chip requirements

- at least 100 mebibytes of contiguous main memory
- memory mapped device interfaces need to be aligned to the page size of 4 kibibytes
- one core local interruptor (clint) with software interrupt pending, real world timer and real world timer comparator fields (msip, mtime, mtimcmp)
- the real world timer has to have a timebase frequency of at least 20 hertz
- either no platform level interrupt controller or just a single one – if multiple are implemented, only the one listed first in the flattened device tree is utilized

If a system on a chip requirement is not met, all hardware threads will idle indefinitely.


# hardware thread requirements

- RISC-V 64 bit architecture
- atomic (A), integer (I), multiply and divide (M), supervisor mode (S) and user mode (U) extensions
- misa register
- page based virtual memory with 39 bit virtual addresses (RISC-V Sv39)

If a hardware thread requirement is not met, only the hardware thread that does not meet the requirements will idle indefinitely.

It is assumed that all hardware threads support the same extensions. The kernel does not treat hardware threads differently depending on their extensions. This potentially causes undefined behaviour, because user programs may be run on a hardware thread that does not support required instruction set extensions.

Currently the instruction set extensions A, D, F, I, M, Q, S, U are supported. Other extensions may behave inappropriately.


# dynamic and static libraries

The purpose of dynamic libraries is to use code within multiple processes while existing only once in main memory, which in turn reduces the memory footprint. However, it makes program files depend on additional files, making program management unintuitive and considering the capacities of modern main memory modules, the advantages of dynamic libraries are considered negligible.

Due to the aforementioned reasons, the decision was made to exclude the functionality of dynamic libraries from the kernel. This means only static libraries are supported and executables will always consist of a single file only.


# names

Multiple kernel tables contain character arrays to store human readable identifications. The kernel does not interpret these, allowing them to contain any value and encoding. They are considered a single block of data and do not contain any organisational variables. This implies, name operations always affect the entire name. For instance, copying a name requires all 256 bytes of the given name to be copied, independent from their content.


# real-time priority

The term “real-time” in regards to process priorities describes the execution of threads that has to be done in a given time frame. Very high priority in the scheduler routine causes threads to be run before threads of lower priority and could be described with “soft real-time”. However, “soft real-time” is a blurry term, that essentially describes the highest priority and is considered misleading. Therefore, the ango kernel labels its four priorities as “low”, “normal”, “high” and “very high”.


# processor affinity

Affinity masks allow the user to define which hardware threads a process is allowed to be run on. Because given processes would run on fewer hardware threads, associated cache is less likely to be overwritten.

The kernel includes the concept of process priorities, to allow the user to specify in which order processes should be run. While affinity masks work quite differently, they try to improve allocation of processing time also. However, affinity masks directly depend on the CPU and hardware thread count, which makes them more difficult to maintain for the kernel and the user. Therefore, processor affinity by affinity masks is not implemented.



# 2 boot

The ango kernel includes any code that is needed to securely expose underlying hardware to user programs and directly follows hardware specific routines that are often stored in on board read only memory. This means, no additional program is needed to be compiled with the kernel.

Including drivers of devices such as the core local interruptor implies kernel growth as different versions arise. This downside is accepted, because you would have to include all boot routines somewhere in the operating system software stack anyway. In special cases, where only a single hardware configuration is expected, the kernel may be modified to individual needs.

Initialization starts in machine mode, as the kernel always runs in machine mode. All hardware threads synchronize with each other and register themselves in the hardware thread table. The first hardware thread to finish registration analyzes underlying hardware, initializes remaining kernel structures and constructs the first processes. Once the kernel structures are initialized and the hardware thread registered itself, the hardware thread enters the main scheduler routine.


# entry expectations

The address of a flattened device tree of version 17 is expected to be given in a0 and machine mode interrupts shall be disabled, to ensure defined behaviour while the kernels exception handler is not initialized yet. Any other register may be undefined and is set by the kernel itself.



# 3 memory management

While the kernel itself addresses physical memory, all processes utilize page based virtual memory with 4096 byte pages and 39 bit virtual addresses (RISC-V Sv39). Except page tables, all kernel structures are allocated at kernel assembly and do not change in size, to ensure full isolation from user memory allocations and predictable memory layout. Any remaining memory is aligned to page boundaries and made available to user programs.


# user memory

All free pages are concatenated to a linked list, where each page contains the address of the succeeding page. The linked list is not sorted and pages are always pushed and popped from the top. At allocation the kernel determines the physical and virtual address of the page, while user programs shall comply with the location of given pages. Moreover, user programs shall be position independent and only assume to be loaded to an address that is aligned to 64 bits.

The address space of processes is divided into user space and device interface space. The device interface space is always located at the uppermost addresses and allows the kernel to map all device interfaces to the address space of any process. The size of the device interface space is the sum of all device interface memory sizes. The remaining addresses make up user space and may contain any data that is specific to the contained user program.

Pages are always mapped to user address spaces with full permissions, because the security of a user program shall not be a concern of the kernel and avoids polluting program binaries with operating system specific data. Also, gigapages, superpages, or megapages are not supported, because they do not add functionallity for the user and cause general overhead in most memory routines.


# address spaces

Each process has its own address space, which maps virtual addresses to physical addresses. An address space gives the contained user program the impression as if it is the only program in main memory and isolates memory operations of a process from another. The amount of bits used to identify each address space may vary depending on the implementation. Therefore, the address space identifier is calculated with the formula:

(maximum address space identifier % process identifier) + 1 = address space identifier


# translation lookaside buffer invalidation

The translation lookaside buffer contains the most common physical to virtual address mappings, ultimately reducing virtual address translation times. However, this causes page table leaf entries to possibly exist multiple times, so that changes to a page table entry may only be present in main memory, but not in translation lookaside buffers. Therefore, on modification of a page table entry, the kernel invalidates all entries of the given address space in the translation lookaside buffer of each hardware thread.

Invalidation of translation lookaside buffer entries are issued in order, meaning, only a single hardware thread can issue an invalidation at a time. This is completely acceptable, since the procedure of invalidation itself synchronizes all hardware threads anyway. For synchronization the kernel maintains 16 bits to identify the process who's address space has to be invalidated and 8 bits to keep track of the amount of hardware threads that still need to invalidate their corresponding page table entries.

The invalidation routine starts at the hardware thread that altered or removed a page table entry. The hardware thread writes the identification of the process the page table entry is part of, to the translation lookaside buffer invalidation fence. Moreover, it resets the fences hardware thread count to the size of the hardware thread table. Now it causes a software interrupt for all other hardware threads and invalidates its own translation lookaside buffer entries.

Each interrupted hardware thread checks the hardware thread count of the translation lookaside buffer fence, which indicates the need of an invalidation by its non-zero value. In turn, the hardware thread loads the process identification, calculates the address space identification and invalidates corresponding translation lookaside buffer entries. Lastly, each hardware thread decrements the hardware thread count of the fence by one and waits for this variable to reach zero. Afterwards, each hardware thread can continue with its normal execution.



# 4 hardware threads

A hardware thread is a single unit of execution and can always contain only one context at a time. The hardware thread table provides memory to each hardware thread, they can keep information about themselves and store temporary data in. This allows each hardware thread to easily obtain information about coexisting hardware threads.

Hardware threads are registered in the hardware thread table at kernel initialization and identified by their index. Hardware thread 0 is reserved to indicate absence of any hardware thread. Furthermore, hardware threads register themselves in the hardware thread table only if their misa register is implemented and set to support the atomic (A), integer (I), multiply/divide (M), supervisor (S) and user (U) extensions, otherwise the corresponding hardware thread is shut down.


# memory mapped registers

Some devices that are needed by the kernel are not hardware thread local and related registers are exposed to multiple hardware threads. Implementations are free to define the address of each device and memory mapped register. Therefore, the kernel writes the address of needed memory mapped registers to corresponding hardware thread elements.

Currently only “riscv,clint0” and “riscv,plic0” are supported. As more devices are implemented memory mapped registers may be added, merged or removed.


# stack

While the kernel covers both machine and supervisor mode, all exceptions are handled in machine mode. This avoids separate stacks for each mode and ultimately the size of each hardware thread element. The stack is filled from the uppermost to the lowermost address contained.

Since all integer registers of rv64 are 64 bits wide the stack was chosen to be a multiple of 64 bits. The total size of the stack is just an estimate of the potentially needed amount of memory any function combination could need. Additionally, making the stack greater than actually needed, allows future adjustments in functions, without immediately causing a stack overflow.



# 5 device interfaces

Device interfaces control communication of user programs with memory mapped devices.

The kernel reads the flattened device tree that was given by the firmware that preceds at system boot. Any node that is a direct child of the “soc” node and contains at least one of the properties “reg” or “interrupts” is translated into a device interface, excluding “clint” and “interrupt-controller”. A device interface can be reserved by one process at a time, which maps associated physical address ranges to the virtual address space of the process. Any interrupts that originate from the device are translated to a message to the process that reserved the corresponding device interface. Device interfaces are identified by their device interface table index. Device interface 0 is reserved to indicate absence of any device interface.

A user program may reserve a device interface and offer its functions to any other user program through inter process communication.


# virtual timer comparator

Real time clocks are expensive to implement and therefore only a single timer is implemented, with one timer comparator register for each hardware thread. The kernel uses the comparator registers itself, to limit execution time of threads. Therefore, one virtual timer comparator register is provided for user programs.

The virtual timer comparator can be reserved by one process at a time. In turn, any thread of the process can modify the virtual timer comparator. The kernel writes a message to the process that reserved the virtual timer comparator if the contained value is less or equal the current time. The value of the virtual timer comparator is never written to the physical timer comparator and only manually checked by the kernel when possible.

The scheduler picks the next thread to run at least every 100 milliseconds, which requires the real time clock to run at 10 hertz or higher. However, to maximize compatibility, the real time clock frequency is not required to be a multiple of 10 hertz, implying that it may be impossible to count exactly 100 milliseconds. This is considered acceptable, since with higher frequencies those inaccuracies become smaller.



# 6 users

A user identifies an individual that operates the computer. Resources that are associated with a user shall be isolated from those of another user. While a user can be associated with a lot of data of various formats, the kernel is only responsible for authenticating each user. Additionally, a single superuser is implemented, which resembles the system itself. The superuser has access to all functions of the user binary interface and shall be unlimited throughout all user programs.

The distinction between user and superuser is made to limit user programs to themselves, while superuser programs are needed to manage the entire system. Access to user and superuser functions has to be enforced by an authentication method, in order to prevent programs from accessing them anyway. Therefore, user authentication is considered a kernel feature and is implemented in the kernel, instead of a user program.

Multiple users can be constructed, but only one can be logged in at a time. In case multiple instances of an operating system are needed the hypervisor extensions should be utilized, which also allows more detailed resource allocation per user.

The user table contains an element for each user, excluding the superuser. Users are identified by their user table index. User 0 is reserved to indicate absence of any user.



# 7 processes

A process is a container for a user program and a logical abstraction of a single problem. This is the main unit the kernel works with when assigning system resources to user programs.

Processes are identified by their index in the process table. Process 0 is reserved to indicate absence of any process.


# hierarchy

Processes are organized in a hierarchy, in which each process can have a single parent process. Processes are destructed as their parent is destructed.


# permissions

Processes with user permissions have limited access to the user binary interface and are destructed as the current user is logged out. The process may acquire superuser permissions at runtime by verifying the superuser password.

Processes with superuser permissions have full access to the user binary interface and are only destructed with their parent or when requested by another process with superuser permissions. Additionally, superuser processes can construct detached processes, meaning the new process has no process as parent. The process may discard its superuser permissions at runtime, without any verification.

User programs shall enforce the aforementioned user/superuser relation, exposing sensitive and user independent functions to the superuser only.



# 8 threads

A thread is the subdivision of a process into asynchronously solvable parts. This allows multiple hardware threads to work on one process simultaneously and makes a process nonlinear.

Threads are identified by their index in the thread table. Thread 0 is reserved to indicate absence of any thread.


# lifetime

Initially threads are "ready", which allows any hardware thread to pick the thread. Picking a thread sets the threads status to "running" and indicates a hardware thread executes the contained workload. If the thread exhausts its quantum, the thread is set to "ready" again, giving other threads a chance to be executed. Alternatively, "running" threads can be transitioned to "paused" by the contained user program, to stall execution of the thread. As soon as the container process receives a message, the "paused" thread is set to "ready" and can be picked again.


# scheduler

The scheduler consists of four queues, one for each process priority, namely "low priority", "normal priority", "high priority" and "very high priority". Each queue is organized as linked list, maintaining a reference to the next thread to pick (front) and the thread that was scheduled last (back). All data of scheduler routines is contained in the thread table, which allows immediate access to the scheduled threads.

As a thread is scheduled, the thread is linked to the back of the scheduler queue that matches its container processes priority. On this way the thread that was scheduled first will be picked first, while the thread that was scheduled last will be picked last.

The picking routine checks the front of each queue for scheduled threads. The scheduler checks the queue of very high priority first, followed by the high priority queue, the normal priority queue and the low priority queue last. The picked thread is removed from the queue and the succeeding element is moved to the front of the queue. This means, a queues elements can only be picked if all queues of higher priority are empty.

Scheduler queues do not have to be filled at all times, which can cause no thread to be picked. In this case, the hardware thread is "timed out", meaning the kernel idles for 100 milliseconds. A time limit ensures the hardware thread does not rely on other hardware threads and eventually continues work on threads that may be scheduled by other hardware threads.

The amount of time a thread is run for is called quantum and is 100 milliseconds for all threads of any priority. When a thread exhausts its quantum it is scheduled anew. The scheduler possibly picks the thread that was just run, in which case the thread is not saved or restored. Instead, execution of the thread is continued right away.


# register tray

The amount of hardware threads is commonly less than the amount of threads that need to be processed. This forces the hardware threads to switch between multiple threads. Therefore, the state of the registers has to be saved when switching from a thread and restored when switching to a thread. The register tray is a range of memory the kernel stores all user registers in, which resemble the current state of the thread.

Optional architecture extensions, such as the single precision floating point extension, are only stored and restored if implemented. Additionally, registers of a particular extension are only stored when modified during execution of the user program. Lastly, store and restore routines are skipped if the scheduler picks the loaded thread again.



# 9 inter process communication

The only inter process communication routine allows user programs to send chunks of data to another process. The kernel is only responsible for assembling the so called message and copying the chunks of data to the target processes address space. Messages contain up to one kibibyte worth of user encoded data.

User programs have to provide an address range the kernel can write messages to, or cannot be target of messages otherwise. Moreover, user programs shall follow the kernel defined message bit layout, but may concatenate any amount of messages to an array. Allocating more messages allows more messages to be received in a given time span and may give the recipient more time to process existing messages. However, each allocated message adds minor overhead, since messages have to be checked for existence individually.


# message array

The message array has to be aligned to 64 bits and may contain any amount of messages. In turn, the user program has to tell the kernel the address and the size of the message array at run time.

The lowermost eight bytes of messages are the existence flag. If the existence flag is zero the kernel may overwrite the message and set the existence flag to a non-zero value. Otherwise, the user program may process the message content and set the existence flag to zero again. The user program shall order memory operations on the message to precede clearing the existence flag.

message byte layout
0 existence flag
8 sender process identifier
16 message content
1040



# 10 user binary interface

The user binary interface allows user programs to access kernel functions through the environment call instruction "ecall". Register a0 always identifies the function to call and remaining registers may be used to pass additional function specific arguments.

3 allocate_memory
Adds an address range in main memory to the caller process. The address of the address range is defined by the kernel and shall not be assumed by the user program, while the size in bytes of the address range is given in register a1. The status is returned in a0 and the address of the allocated address range in a1.

4 free_memory
Removes an address range in main memory from the caller process. The address of the address range is given in register a1 and the size in bytes of the address range in a2. User programs shall always free address ranges as they were allocated, because the kernel may align address ranges internally and otherwise more addresses may be freed than requested. This function does not fail and does not return any values.